{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesarry imports\n",
    "import pandas as pd\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# settings to display all columns\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [\"XS\", \"S\", \"M\", \"L\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"../data/final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = final_df[final_df[\"vehicleType\"] == \"car\"]\n",
    "\n",
    "# Add the vehicle class\n",
    "classes = { 'BMW 1er': \"M\",\n",
    " 'BMW 2er Active Tourer': \"M\", 'BMW 2er Cabrio': \"L\", 'BMW I3': \"M\",\n",
    "       'BMW X1': \"L\", 'BMW X2': \"L\", 'MINI 3-tuerer': \"S\", 'MINI 5-tuerer': \"S\",\n",
    "       'MINI Cabrio': \"S\", 'MINI Clubman': \"S\", 'MINI Countryman': \"S\",\n",
    "       'Mercedes-Benz A-Klasse': \"M\", 'Mercedes-Benz B-Klasse': \"M\",\n",
    "       'Mercedes-Benz GLA': \"M\", 'bmw 1er': \"M\", 'bmw 2er active tourer': \"M\",\n",
    "       'bmw 2er cabrio': \"L\", 'bmw i3': \"M\", 'bmw x1': \"L\", 'bmw x2': \"L\", 'mini 3-tuerer': \"S\",\n",
    "       'mini 5-tuerer': \"S\", 'mini cabrio': \"S\", 'mini clubman': \"S\", 'mini countryman': \"S\",\n",
    "       'smart fortwo 3rd generation': \"XS\"}\n",
    "\n",
    "car_df[\"class\"] = car_df[\"model\"].apply(lambda model: classes[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_src_columns = [\"Unter 18\", \"18 - 29\",\"30 - 49\",\"50 - 64\",\"65 und älter\"]\n",
    "hh_src_columns = [\"Einpersonenhaushalte (Singlehaushalte)\", \"Paare ohne Kind(er)\", \"Alleinerziehende Elternteile\", \"Paare mit Kind(ern)\", \"Mehrpersonenhaushalte ohne Kernfamilie\"]\n",
    "\n",
    "tmp_df = car_df[[*age_src_columns, *hh_src_columns, \"distance\", \"class\", \"Bezirk\"]]\n",
    "\n",
    "# Calculate the distribution classes\n",
    "def calculate_dist(columns: list[str], prefix: str):\n",
    "  sum = tmp_df[columns].sum(axis=1)\n",
    "  for (i, c) in enumerate(columns):\n",
    "    tmp_df[f\"{prefix}_{i + 1}\"] = (tmp_df[c] / sum)\n",
    "\n",
    "calculate_dist(age_src_columns, \"age\")\n",
    "calculate_dist(hh_src_columns, \"hh\")\n",
    "\n",
    "# Now drop the unused classes\n",
    "learning_df = tmp_df.drop([*age_src_columns, *hh_src_columns, \"Bezirk\"], axis=1)\n",
    "\n",
    "# Also drop malformed entries\n",
    "learning_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also create the bezirks data for the stations in the simulation stage\n",
    "bezirk_df = tmp_df.drop([*age_src_columns, *hh_src_columns, \"class\", \"distance\"], axis=1)\n",
    "print(bezirk_df.groupby(\"Bezirk\").count().sort_values(\"age_1\"))\n",
    "bezirk_df = bezirk_df.groupby(\"Bezirk\").mean()\n",
    "\n",
    "# Aaand normalize columns\n",
    "def normalize_columns(columns):\n",
    "  sum = bezirk_df[columns].sum(axis=1)\n",
    "  for c in columns:\n",
    "    bezirk_df[c] = bezirk_df[c] / sum\n",
    "\n",
    "normalize_columns([f\"age_{i}\" for i in range(1, 6)])\n",
    "normalize_columns([f\"hh_{i}\" for i in range(1, 6)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"Under 18 Years\", \"18-29 Years\", \"30-49 Years\", \"50-64 Years\", \"Over 65 Years\", \"Single Household\", \"Pairs\", \"Single Parents\", \"Parents with children\", \"Multiperson household\"]\n",
    "# bezirk_df[[f\"hh_{i}\" for i in range(1, 6)]].sum(axis=1)\n",
    "bezirk_df.to_latex(\"../paper/Appendices/district-table.tex\", header=header, longtable=True, label=\"table:Districts\", float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bezirk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_districts = [\"Pankow\", \"Reinickendorf\", \"Friedrichshain-Kreuzberg\", \"Charlottenburg-Wilmersdorf\"]\n",
    "\n",
    "relevant_data = car_df.loc[car_df[\"Bezirk\"].isin(simulation_districts), \"datetime_start\"]\n",
    "\n",
    "r = pd.to_datetime(relevant_data,errors='coerce', utc=True)\n",
    "hour_df = pd.DataFrame(data={\"day\": r.dt.date, \"hour\": r.dt.hour, \"id\": relevant_data.index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = hour_df.groupby([\"day\", \"hour\"]).count()\n",
    "# palette = sns.light_palette(\"#786fa6\")\n",
    "# sns.barplot(x=hd.index, y=hd.values, palette=palette\n",
    "daily_demand = hd.groupby(\"hour\").mean().round()\n",
    "\n",
    "palette = sns.color_palette([\"#3B3659\", \"#4C4672\", \"#5C558B\", \"#6F67A2\", \"#8781B1\"])\n",
    "sns.barplot(data=daily_demand, x=daily_demand.index, y=\"id\", palette=palette)\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylabel(\"Average number of rentals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.to_datetime(car_df[\"datetime_start\"], utc=True)\n",
    "end = pd.to_datetime(car_df[\"datetime_end\"], utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = car_df[\"distance\"] / (end - start).dt.seconds\n",
    "diff = diff * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.replace([np.inf, -np.inf], np.nan).dropna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df[\"distance\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out the availability of classes\n",
    "unique_cars = car_df.groupby(\"class\")[\"id\"].nunique()\n",
    "num_of_dp = learning_df.groupby(\"class\")[\"class\"].count()\n",
    "min_class = num_of_dp.idxmin()\n",
    "\n",
    "\n",
    "def truncate_shuffle(c):\n",
    "  num = num_of_dp[c]\n",
    "  unique = unique_cars[c]\n",
    "\n",
    "  scale = unique_cars[c] / unique_cars[min_class]\n",
    "  truncated_num = round(scale * num_of_dp[min_class])\n",
    "\n",
    "  a = learning_df.loc[learning_df[\"class\"] == c, :]\n",
    "  shuffle(a)\n",
    "  a = a[:80000] # truncated_num\n",
    "\n",
    "  print(c, num, unique, scale, truncated_num, a.shape)\n",
    "  return a\n",
    "\n",
    "# learning_df = pd.concat([truncate_shuffle(c) for c in C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df.groupby(\"class\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X = learning_df.loc[:, learning_df.columns != \"class\"]\n",
    "Y = learning_df.loc[:, learning_df.columns == \"class\"][\"class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = make_pipeline(MinMaxScaler(), ComplementNB())\n",
    "clf.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "nn_clf = make_pipeline(StandardScaler(), MLPClassifier(random_state=1, max_iter=1200))\n",
    "nn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "sgd_clf = make_pipeline(StandardScaler(),\n",
    "                    SGDClassifier(max_iter=1000, tol=1e-3, class_weight=\"balanced\", loss=\"log\"))\n",
    "\n",
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.inspection import permutation_importance\n",
    " \n",
    "# Test the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "imps = permutation_importance(clf, X_test, y_test)\n",
    "print(imps.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score\n",
    "# Test the classifier\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import Simulation\n",
    "\n",
    "p = 1 / daily_demand[\"id\"]\n",
    "station_data = bezirk_df.loc[bezirk_df.index.isin(simulation_districts), :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_r = [(alpha, Simulation(station_data=station_data, p=p, alpha=alpha, capacity=5, pred=clf.predict_proba)) for alpha in np.arange(0.01, 0.05, 0.002)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df = pd.DataFrame(data=map(lambda a: [a[0], a[1].td, a[1].urr, a[1].pi], alpha_r), columns=[\"alpha\", \"TD\", \"URR\", \"PI\"])\n",
    "alpha_df[\"alpha\"] = alpha_df[\"alpha\"].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_r = [(c, Simulation(station_data=station_data, p=p, alpha=0.05, capacity=c, pred=clf.predict_proba)) for c in np.arange(2, 50, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_df = pd.DataFrame(data=map(lambda a: [a[0], a[1].td, a[1].urr, a[1].pi], capacity_r), columns=[\"Capacity\", \"TD\", \"URR\", \"PI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=capacity_df[\"Capacity\"], y=capacity_df[\"TD\"], palette=palette)\n",
    "sns.pointplot(x=capacity_df[\"Capacity\"], y=capacity_df[\"URR\"], palette=palette)\n",
    "sns.pointplot(x=capacity_df[\"Capacity\"], y=capacity_df[\"PI\"], palette=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_plot(df, index, xlabel):\n",
    "  fig, ax = plt.subplots(1, 3, figsize=(21, 7),constrained_layout=True )\n",
    "  c = [\"#4C4672\", \"#5C558B\", \"#6F67A2\"]\n",
    "  \n",
    "  sns.pointplot(x=df[index], y=capacity_df[\"URR\"], color=c[0], ax=ax[0])\n",
    "  sns.pointplot(x=df[index], y=capacity_df[\"PI\"], color=c[1], ax=ax[1])\n",
    "  sns.pointplot(x=df[index], y=capacity_df[\"TD\"], color=c[2], ax=ax[2])\n",
    "  fig.autofmt_xdate()\n",
    "  for a in ax:\n",
    "    a.set_xlabel(xlabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_plot(alpha_df, \"alpha\", \"Substitution effect α\") # \"α\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_plot(capacity_df, \"Capacity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Simulation(station_data=station_data, p=p, alpha=0.003, capacity=30, pred=clf.predict_proba)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 9), constrained_layout=True )\n",
    "for station, ax in zip(s.stations, axs.flatten()):\n",
    "  # ax = axs[i]\n",
    "  # This is just for the ide\n",
    "  ax: plt.Axes = ax\n",
    "  ax.set_title(station.name)\n",
    "  ax.set_xlim(0, 24)\n",
    "  ax.set_xlabel(\"Simulation time\")\n",
    "  ax.set_ylabel(\"Store Delta State\")\n",
    "  for (c, df) in station.history_df.items():\n",
    "    sns.lineplot(x=df.index / 60, y=df[\"amount\"].values, ax=ax)\n",
    "  ax.legend(labels=station.history_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.print_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.predict_proba([[5, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_class(i, name):\n",
    "  car_df[f\"age_{i}\"] = car_df[name] / car_df[\"Einheiten insgesamt\"]\n",
    "\n",
    "age_class(1, \"Unter 18\")\n",
    "age_class(2, \"18 - 29\")\n",
    "age_class(3, \"30 - 49\")\n",
    "age_class(4, \"50 - 64\")\n",
    "age_class(5, \"65 und älter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_curr = [\"Erwerbstätige / Monatliches Nettoeinkommen unter 900\", \"Erwerbstätige / Monatliches Nettoeinkommen 900 – 1500\", \"Erwerbstätige / Monatliches Nettoeinkommen 1500 und mehr\"]\n",
    "\n",
    "car_df[\"income_total\"] = car_df[income_curr].sum(axis=1)\n",
    "\n",
    "def income_class(i, name):\n",
    "  car_df[f\"income_{i}\"] = car_df[name] / car_df[\"income_total\"]\n",
    "\n",
    "for (i, name) in enumerate(income_curr):\n",
    "  income_class(i + 1, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = { 'BMW 1er': \"M\",\n",
    " 'BMW 2er Active Tourer': \"M\", 'BMW 2er Cabrio': \"L\", 'BMW I3': \"M\",\n",
    "       'BMW X1': \"L\", 'BMW X2': \"L\", 'MINI 3-tuerer': \"S\", 'MINI 5-tuerer': \"S\",\n",
    "       'MINI Cabrio': \"S\", 'MINI Clubman': \"S\", 'MINI Countryman': \"S\",\n",
    "       'Mercedes-Benz A-Klasse': \"M\", 'Mercedes-Benz B-Klasse': \"M\",\n",
    "       'Mercedes-Benz GLA': \"M\", 'bmw 1er': \"M\", 'bmw 2er active tourer': \"M\",\n",
    "       'bmw 2er cabrio': \"L\", 'bmw i3': \"M\", 'bmw x1': \"L\", 'bmw x2': \"L\", 'mini 3-tuerer': \"S\",\n",
    "       'mini 5-tuerer': \"S\", 'mini cabrio': \"S\", 'mini clubman': \"S\", 'mini countryman': \"S\",\n",
    "       'smart fortwo 3rd generation': \"XS\"}\n",
    "\n",
    "car_df[\"class\"] = car_df[\"model\"].apply(lambda model: classes[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_columns = [f\"age_{i}\" for i in range(1, 6)]\n",
    "income_columns = [f\"income_{i}\" for i in range(1, 4)]\n",
    "\n",
    "fdf = car_df[[*age_columns, *income_columns, \"class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"XS\" is overpopulated\n",
    "sns.countplot(data=car_df, x=\"model\", order=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(car_df, x=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palette = sns.light_palette(\"#786fa6\")\n",
    "ax = sns.boxplot(data=learning_df, palette=palette)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df[\"model_lc\"] = car_df[\"model\"].apply(lambda a: a.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,4)) # this creates a figure 8 inch wide, 4 inch high\n",
    "\n",
    "palette = sns.light_palette(\"#786fa6\")ax = sns.countplot(data=car_df, x=\"model_lc\", palette=palette, order=car_df[\"model_lc\"].value_counts().index)\n",
    "ax.set_ylim(0, 1200000)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.xlabel(\"Model class name\")\n",
    "plt.ylabel(\"Number of rentals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df[\"model_lc\"].value_counts()[1:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fleet_size = car_df[[\"model_lc\", \"id\"]].groupby(\"model_lc\").nunique()\n",
    "fleet_size.sort_values(by=\"id\", ascending=False, inplace=True)\n",
    "\n",
    "ax = sns.barplot(x=fleet_size.index, y=fleet_size.values.reshape(1, -1)[0], palette=palette)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"Model class name\")\n",
    "plt.ylabel(\"Number of unique vehicles\")\n",
    "plt.show()\n",
    "# fleet_size.index, fleet_size.values.reshape(1, -1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fleet_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fleet_ids = fleet_size[\"id\"]\n",
    "fleet_size.max(), fleet_size.min(), fleet_size.sum(), fleet_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = fdf.groupby(\"class\").count().min(axis=1).min()\n",
    "\n",
    "def truncate_class(c):\n",
    "  a = fdf[fdf[\"class\"] == c];\n",
    "  shuffle(a)\n",
    "  a = a[:count]\n",
    "  return a\n",
    "\n",
    "fdf = pd.concat([truncate_class(c) for c in C])\n",
    "fdf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now not anymore\n",
    "sns.countplot(data=fdf, x=\"class\", order=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "X = fdf[[*age_columns, *income_columns]]\n",
    "Y = fdf[\"class\"]\n",
    "\n",
    "# Oversample using SMOTE\n",
    "# sm = SMOTE(random_state=42)\n",
    "# x_smote, y_smote = sm.fit_resample(X, Y)\n",
    "\n",
    "# enn = EditedNearestNeighbours()\n",
    "# x_train_enn, y_train_enn = enn.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "clf_classes = clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score\n",
    " \n",
    "# Test the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "# print(accuracy_score(y_test,y_pred))\n",
    "# print(\"Precision Score : \",precision_score(y_test,y_pred, \n",
    "#                                            pos_label='positive',\n",
    "#                                            average='micro'))\n",
    "# print(\"Recall Score : \",recall_score(y_test,y_pred, \n",
    "#                                            pos_label='positive',\n",
    "#                                            average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = car_df[[\"Bezirk\", *age_columns, *income_columns]].groupby(\"Bezirk\")\n",
    "districts = districts.mean()\n",
    "districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out and normalize data per sector\n",
    "def normalize_columns(columns):\n",
    "  total = districts[columns].sum(axis=1)\n",
    "  for c in columns:\n",
    "    districts[c] = districts[c] / total\n",
    "\n",
    "normalize_columns(age_columns)\n",
    "normalize_columns(income_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predice_choices(d, alpha):\n",
    "  p = clf.predict_proba([d])[0]\n",
    "  i = p.argmax()\n",
    "  print(p)\n",
    "  p_max = p[i]\n",
    "\n",
    "  choices = filter(lambda a: p[a[0]] >= p_max - alpha, enumerate(clf_classes))\n",
    "  choices = map(lambda a: a[1], choices)\n",
    "\n",
    "  return list(choices)\n",
    "\n",
    "\n",
    "def predict_district(name: str, alpha: float):\n",
    "  return predice_choices(districts.loc[name][[*age_columns, *income_columns]], alpha)\n",
    "  \n",
    "\n",
    "print([(on, predict_district(on, 0.04)) for on in districts.index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.to_datetime(car_df[\"datetime_start\"][0:50000], errors=\"raise\")  \n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = car_df[0:50000].groupby(dt.dt.hour).count()[\"id\"]\n",
    "sns.barplot(x=v.index, y=v.values, palette=palette)\n",
    "\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylabel(\"Rides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predice_choices([0, 1, 0, 0, 0, 0, 0, 1], 0.1), clf_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predice_choices([0, 0, 0, 1, 0, 0, 1, 0], 0.1), clf_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predice_choices([0, 0, 0.3, 0, 0, 0, 0, 1], 0.1), clf_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(XGBClassifier(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = car_df[[\"datetime_start\", \"datetime_end\"]]\n",
    "times.min(), times.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df[\"provider\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed12f06e45608676005dc967d1975705358fa64279e345b8c2fbaa7d4b34d0db"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
